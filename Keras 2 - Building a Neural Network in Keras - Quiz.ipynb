{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this quiz, we will build a simple multi-layer feedforward neural network to solve the XOR problem.  \n",
    "\n",
    "Recall XOR  \n",
    "```\n",
    "------------------  \n",
    "A  |  B  | A XOR B  \n",
    "------------------  \n",
    "0     0       0   \n",
    "0     1       1   \n",
    "1     0       1   \n",
    "1     1       0   \n",
    "```  \n",
    "\n",
    "Here's what we are going to do:  \n",
    "\n",
    ">1. Set the first layer to a `Dense()` layer with an output width of 8 nodes and the `input_dim` set to the size of the training samples (in this case 2).\n",
    ">2. Add a `tanh` activation function.  \n",
    ">3. Set the output layer width to 1, since the output has only two classes. (We can use 0 for one class and 1 for the other).\n",
    ">4. Use a `sigmoid` activation function after the output layer.\n",
    ">5. Run the model for 50 epochs.  \n",
    "\n",
    "This should give you an accuracy of 50%. That's OK, but certainly not great. Out of 4 input points, we are correctly classifying only 2 of them. Let's try to change some parameters around to improve. For example, you can increase the number of epochs. You'll pass this quiz if you get 75% accuracy.  \n",
    "\n",
    "Finished work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "\n",
      "Accuracy:  1.0\n",
      "\n",
      "Predictions:\n",
      "[[0.06305031]\n",
      " [0.8665381 ]\n",
      " [0.9114123 ]\n",
      " [0.11303615]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "tf.python_io.control_flow_ops = tf\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Trained data: X and y\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]]).astype('float32') # (4,2)\n",
    "y = np.array([[0],[1],[1],[0]]).astype('float32') # (4,1)\n",
    "\n",
    "# Initial setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "# Building the model\n",
    "xor = Sequential()\n",
    "\n",
    "# 1. Set the first layer to a Dense() layer with an output width of 8 nodes \n",
    "#    and the input_dim set to the size of the training samples (in this case 2).\n",
    "xor.add(Dense(8, input_dim = X.shape[1]))\n",
    "\n",
    "# 2. Add a tanh activation function.\n",
    "xor.add(Activation('tanh'))\n",
    "\n",
    "# 3. Set the output layer width to 1, since the output has only two classes. \n",
    "#    (We can use 0 for one class and 1 for the other).\n",
    "xor.add(Dense(1))\n",
    "\n",
    "# 4. Use a sigmoid activation function after the output layer.\n",
    "xor.add(Activation('sigmoid'))\n",
    "\n",
    "# Specify loss as \"binary_crossentropy\", optimizer as \"adam\",\n",
    "# and add the accuracy metric\n",
    "xor.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model architecture\n",
    "xor.summary()\n",
    "\n",
    "# Fitting the model\n",
    "#history = xor.fit(X, y, epochs=50, verbose=0) \n",
    "# Obtained Accuracy:  0.5\n",
    "history = xor.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Scoring the model\n",
    "score = xor.evaluate(X, y)\n",
    "print('\\nAccuracy: ', score[-1])\n",
    "\n",
    "# Checking the predictions\n",
    "print('\\nPredictions:')\n",
    "print(xor.predict_proba(X))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
