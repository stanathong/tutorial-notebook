{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network in Keras  \n",
    "\n",
    "### Sequential Model  \n",
    "\n",
    "```\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "```\n",
    "\n",
    "The `keras.models.Sequential` class is a wrapper for the neural network model that treats the network as a sequence of layers. It implements the Keras model interface with common methods like `compile()`, `fit()`, and `evaluate()` that are used to train and run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers  \n",
    "\n",
    "The Keras Layer class provides a common interface for a variety of standard neural network layers. There are fully connected layers, max pool layers, activation layers, etc. We can add a layer to a model using the model's `add()` method.  \n",
    "\n",
    "For example, a simple model with a single hidden layer might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "# X shape: (num_rows, num_cols), where the training data are stored as row vectors\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]], dtype = np.float32) # shape: (4,2)\n",
    "\n",
    "# y must have an output vector for each input vector\n",
    "y = np.array([[0], [0], [0], [1]], dtype = np.float32) # shape: (4,1)\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Layer - Add an input layer of 32 nodes with the same input shape \n",
    "#  as the training samples in X i.e. X.shape[1] = 2\n",
    "model.add(Dense(32, input_dim = X.shape[1]))\n",
    "\n",
    "# Add a softmax activation layer\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 2nd Layer - Add a fully connected output layer, with 1 means the number of output\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Add a sigmoid activation layer\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Keras requires the input shape to be specified in the first layer__, while the shape of all other layers will be automatically inferred. __We need to explicitly set the input dimensions for the first layer.__  \n",
    "\n",
    "The first hidden layer, `model.add(Dense(32, input_dim = X.shape[1]))` creates 32 nodes which each expect 2-element vectors as inputs (i.e. `X.shape[1]` which is 2). Each layer takes the outputs from the previous layer as inputs and pipes to the next layer. This chain of passing output to the next layer continues until the last layer, which is the output of the model. From the code above, the output has dimension 1, `model.add(Dense(1))`.  \n",
    "\n",
    "The activation layer is defined as `softmax`, `model.Add(Activation('softmax'))`.  \n",
    "\n",
    "Note that the two lines:  \n",
    "\n",
    "```\n",
    "model.add(Dense(32, input_dim = X.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "```\n",
    "\n",
    "can be combined into `model.add(Dense(32, activation='softmax'))`, but it is common to explicitly separate the activation layers because it allows direct access to the outputs of each layer before the activation is applied.  \n",
    "\n",
    "Once we have our model built, __we need to compile it before it can be run__. Compiling the Keras model calls the backend (tensorflow, theano, etc.) and binds the optimizer, loss function and other parameters required before the model can be run on any input data.  \n",
    "\n",
    "We'll specify the loss function to be `categorical_crossentropy` which can be used when there are only two classes, and specify `adam` as the optimiser.  \n",
    "\n",
    "Finally, we specify what metrics we want to evaluate the model with. Here we'll use `accuracy`.  \n",
    "\n",
    "`model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])`  \n",
    "\n",
    "We can see the resulting model architecture with the following command:  \n",
    "\n",
    "`model.summary()`  \n",
    "\n",
    "The model is trained with the `fit()` method, in which we have to specify the number of training epochs and the message level (how much info we want to display on the screen during training).  \n",
    "\n",
    "`model.fit(X, y, nb_epoch=1000, verbose=0)`  \n",
    "\n",
    "Finally, we can use the following command to evaluate the model:  \n",
    "\n",
    "`model.evaluate()`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
